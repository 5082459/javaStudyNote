# 并发编程艺术 {ignore}
[toc]

## 第一章 并发编程的挑战

### 1.1 上下文的切换

即使单核处理器支持多线程执行代码，CPU通过给每一个线程分配CPU时间片（几十ms）段来实现多线程的机制。来回切换线程（保存和加载过程）会有开销。

### 1.2 死锁
定义：两个或多个线程同时等待对方释放锁时，会产生死锁。
避免方法：
- 避免一个线程同时获得多个锁。
- 避免一个线程在锁内同时占用多个资源，尽量保证一个锁只占用一个资源。
- 使用定时锁，lock.tryLock(timeout)。
- 对数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况。

### 1.3 资源限制

## 第二章 java并发机制的底层实现原理
java代码编译后会变成字节码，字节码被类加载器加载到JVM里，JVM执行字节码最终转化为汇编在CPU上执行。

### 2.1 volatile的应用

1. colatile的定义与实现原理
- 定义：如果一个变量被声明为volatile,所有线程看到这个变量的只是一致的。

CPU的术语定义
![](images/2019-09-03-21-12-51.png)

- 实现原理：
在对声明了volatile变量进行读写操作时，JVM会向处理器发送一条Lock前缀指令，Lock前缀指令的作用：
（1）Lock前缀指令会引起处理器将缓存写到内存中。
（2）一个处理器的缓存写到内存会导致其他处理器的缓存无效。

2. volatile 的使用优化
**一个对象引用占四个字节**
追加64个字节能够提高并发效率，因为追加64个字节使得队列的头和尾不在同一个高速缓存行内，修改头或尾时只会锁定整个缓冲行，从而使得一个队列的头和尾可以同时被访问修改。

### 2.2 synchronized的实现原理
**重量级锁**
- synchronized实现同步的基础：java中的每一个对象都可以作为锁。
    - 对于普通同步方法，锁时当前**实例对象**
    - 对于静态同步方法，锁是当前类的**class对象**
    - 对于同步方法块，锁是**Sychronized括号里面配置的对象**
    当以一个线程访问同步代码块时，他首先需要获得锁，退出或抛出异常时必须释放锁。

JVM基于进入和退出Monitor对象来实现方法同步和代码块同步。但实现细节不一样，代码块同步是使用monitorenter和monitorexit指令来实现。
monitorenter指令在编译后插入到同步代码块开始位置，而monitorexit指令插入到方法借宿和异常出，jvm要保证每一个monitorenter必须有一个对应的monitorexit与之配对。任何一个对象都有一个monitor与之关联，当一个monitor被持后，它将处与锁定状态。线程执行到monitorenter指令时，将会尝试获取对应monitor的所有权，即尝试获得对象的锁。

&emsp;&emsp;**总结：sychronized关键字会使得代码在编译后将插入monitorenter和monitorexit指令。每一个对象都有与之关联的monitor对象，当线程执行到monitorenter指令时，将会尝试获取monitor的所有权，即获得锁，执行到monitorexit时，将会释放锁。monitorenter与monitorexit成对存在。**

2.2.1 Java对象头
&emsp;&emsp;sychronized用的锁是存在Java对象头里面的。
数组对象头：3个字宽存储对象头 32位虚拟机一个字宽4个字节。
非数组对象：2个字宽存储对象头 64位虚拟机一个字宽8个字节

2.2.2 锁的升级
为减小获得锁和释放锁带来的性能消耗，1.6以后引入偏向锁和轻量级锁。
锁的级别：无锁状态$\longrightarrow$偏向锁状态$\longrightarrow$轻量级锁状态$\longrightarrow$重量级锁状态。
**随竞争激烈程度提升，但只能升级，不能降级**
1. 偏向锁
当一个线程来访问锁时，会在头对象和栈帧中的所记录里存储锁偏向的线程ID，以后该线程在进入和退出同步代码块时不需要尽进行Compare and Swap（CAS）操作来加锁解锁。只需测试对象头中的MARk Word里是否存储着指向当前线程的线程锁。如果测试成功，则表示该线程已经获得锁，如果测试失败，则测试Mark Word中的偏向锁标识是否设置为1，若果没有，则使用CAS竞争锁，如果设置了，则尝试使用CAS将对象头指向该线程。
-偏向锁的撤销
当有其他线程尝试竞争锁的时候偏向锁的持有线程才会释放锁，偏向锁的撤销需要在全局安全点（没有字节码执行）时间上才能进行。
2. 轻量级锁
- 轻量级加锁：
在线程在执行同步代码块之前，JVM会现在当前线程的栈帧中创建用于存储所记录的空间，并且将对象头中的MArk Word复制到锁记录中。然后线程尝试使用将CAS将对象头中的Mar看word替换成指向锁记录的指针。若果成功，当前线程获得锁，否则表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。
**每一个访问同步代码块的线程，将对象头中的Mark Word复制到线程的Display Mark word 中，成功则获得锁，否则自选取锁。**
- 轻量级解锁：
轻量级解锁时，会使原子的CAS操作将会Display Mark Word替换回到对象头Mark Word，若果成功，则表示没有竞争发生。若果失败，则表示当前锁存在竞争，锁就会膨胀成重量级锁。
**当某个线程执行完同步体后，会将Display Mark Word替换到对象头的Mark Word，若果没有线程竞争，则直接替换成功，否则替换失败，升级为重量级锁**

锁的优缺点：
锁|优点|缺点|适应场景
:-:|:-:|:-:|:-:
偏向锁|加锁解锁不需要额外消耗，执行同步代码块和非同步代码块相比仅存在纳秒级差别|若果出现锁的竞争，会带来额外撤销消耗|单线程访问同步代码块场景
轻量级锁|竞争时线程不会阻塞，提高程序的相应速度|若果始终无法获取锁则会消耗CPU资源|追求响应时间同步代码块执行速度非常快
重量级锁|竞争线程不适用自旋，不会消耗CPU|线程阻塞，相应时间缓慢|追求吞吐量，同步代码块执行速度较慢

### 2.3 原子操作的实现原理
原子操作：不可中断的一个或一系列操作
1. 术语定义

术语名称|解释
:-:|:-:
缓存行|缓存的最小操作单位
比较和交换|CAS操作，比较新旧数值是否有变化，有则发生交换
CPU流水线|指令处理流水线，一个CPU时钟内完成一条指令
内存顺序冲突|一般由假共享引起，假共享是指多个CPU同时修改同一缓存行的不同部位而引起其中一个CPU的操作无效，当出现内存顺序冲突时，CPU必须清空流水线

2. 处理器如何实现原子操作
32位IA-32处理器使用基于对**缓存加锁**和**总线加锁**的方式来实现多处理器之间的原子操作。
- 总线加锁：当一个线程处理一个变量时，会在总线上释放一个lock信号，当其他处理器请求访问内存时会被阻塞，实现独占共享资源。（**大家都别取数据**）
- 缓存锁定：锁定缓存行，执行完操作时修改内部的内存地址，并使用缓存一致性时其他CPU缓存无效。

CAS实现原子操作的三大问题
(1) ABA问题，解决：在变量前追加版本号
(2) 循环时间长，开销大。如果自旋CAS长时间不成功，会给CPU带来非常大的执行开销。解决：使用pause指令延时流水线，避免在退出循环因内存冲突引起CPU流水线被清空
(3) 只能保证一个共享变量的原子操作

## 第三章 java内存模型

### 3.1 Java内存模型的基础
3.1.1 并发模型的两个关键问题
线程间的**通信**和**同步**问题。
线程通信机制：
- 共享内存：公共状态
- 消息传递：线程之间发送消息

- 同步：用于控制不同线程间发生相对顺序的机制

3.1.2 Java内存模型的抽象结构
所有示例，静态域和数组元素都存在堆中，对在线程之间共享。
局部变量，方法定义参数和异常处理参数不会在线程之间共享，每一个线程都有自己的本地内存（local memory）存放共享变量的副本，本地内存是JVM的一个抽象概念，并不是真实的存在的。

3.1.3 从源代码到指令序列的重排序
（1）编译器优化的重排序，编译器在不改变单线程语义的情况下，可以重新安排语句顺序。
（2）指令级并行的重排序
（3）内存系统的重排序

3.1.4 并发编程的模型分类

3.15. happens-before：前一个操作（执行结果）对后一个操作可见。

### 3.2 重排序
编译器和处理器为优化程序性能而对指令进行重排序。
3.2.1 数据依赖性
若果两个操作同时访问同一个变量，而这两个操作有一个为写操作，则这两个操作之间存在数据依赖。

3.2.2 as-if-serial语义：不管怎么重排序（单线程）程学的执行结果不能改变。
编译器和处理器不会对存在数据依赖的操作进行重排序。

3.2.4 多线程中，若存在控制依赖的操作重排序，可能会改变程序的执行结果。

### 3.3 顺序一致性
3.3.1 数据竞争：一个线程写一个变量的同时另一个线程读同一个变量，并且读写没有同步排序。
3.3.2 顺序一致性内存模型
- 一个线程中的所有操作必须按照程序的顺序来执行
- 不管是否同步，所有线程都只能看到一个单一的操作顺序，在顺序一致性模型中，每一个操作都必须是原子执行并且对所有线程可见。（任何时间只能有一个线程能够连接到该内存）。

**JVM中语序临界区内重排序**

3.3.4 最小安全性
JVM不保证未同步程序的执行结果和该程序在顺序一致性模型中的执行结果一致。保证执行结果一致需要禁止大量的编译器，处理器的优化。

每次处理器的和内存之间的数据传输都是通过一系列步骤来完成：总线事务。总线会同步试图并发执行的总线事务。

### 3.4 volatile 的内存语义
volatile声明的变量，可以看成对改变量的单个读写做了同步。
具有特性：
- 可见性
- 原子性

当写一个volitile变量时，JVM会把该线程的本地缓存共享变量刷新到主内存
当读一个volatile变量时，JVM会对应本地的内存无效化。

3.4.4 内存语义的实现
屏障插入策略：（防止重排序影响结果）
·在每个volatile写操作的前面插入一个StoreStore屏障。
·在每个volatile写操作的后面插入一个StoreLoad屏障。
·在每个volatile读操作的后面插入一个LoadLoad屏障。
·在每个volatile读操作的后面插入一个LoadStore屏障。


### 3.5 锁的内存语义

3.5.1 锁的释放-获取建立的happens-before的关系
锁除了让临界区互斥执行以外，还可以让释放锁的线程向获取同一锁的线程发送消息。

**锁的释放和获取总结**
- 线程a释放一个锁，实质上是线程a向接下来要获取这个锁的某个线程发出了信息（a线程对共享变量锁做的修改）
- 线程b获得锁，实质上是线程b接受到某线程发出释放锁的消息（修改消息）

3.5.3 
- lock指令执行时会锁住总线。
- 禁止该指令与之前和之后的续写指令进行重排序
- 刷新缓存

### 3.6 final域的内存语义
3.6.1 final域的重排序规则
（1）在构造函数内对一个final域的写入，与之随后把这个被构造对象的引用赋值给一个变量，这两个操作不可重排序。
（2）初次读一个包含final域的引用，与随后初次读这个final域，这两个操作之间不能重排序

### 3.7 happens-before
JMM向程序员提供的happens-before规则
JMM其实是在遵循一个基本原则：只要不改变程序的执行结果（指的是单线程程序和正确同步的多线程程序），
编译器和处理器怎么优化都行。

3.7.3 happens-before规则
1）程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。
2）监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。
3）volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的
读。
4）传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。
5）start()规则：如果线程A执行操作ThreadB.start()（启动线程B），那么A线程的
ThreadB.start()操作happens-before于线程B中的任意操作。
6）join()规则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作
happens-before于线程A从ThreadB.join()操作成功返回。

### 3.8 双重检查锁定与延迟初始化

